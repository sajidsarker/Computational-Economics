\documentclass{article}

\usepackage[margin=1.5in]{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{color}
\usepackage{placeins}
\usepackage{graphicx}
\graphicspath{ {/home/sajid/Desktop/Computational-Economics/Problem Set 2} }

\title{Computational Economics: Problem Set 2}
\author{S M Sajid Al Sanai}
\date{June 18, 2019}

\begin{document}

\maketitle
\pagenumbering{arabic}
\tableofcontents

\lstset{
	frame=lines,
	basicstyle=\small\sffamily,
	tabsize=4,
	columns=fixed,
	showstringspaces=false,
	showtabs=false,
	keepspaces,
	commentstyle=\color{red},
	keywordstyle=\color{blue}
}

\newpage

\section{Dynamic Entry and Exit Game}

\subsection{Choice Probabilities}

There are a total of $(6)$ distinct choice probabilities which are faced by firms. These represent the probability a particular firm $i$ chooses to take a specific action $a_{it}$ as a function of the current demand state $M_{t} \in s_t=\big( a_{1t-1}, a_{2t-1}, M_t \big)$ faced.

Our profit function is additive in our standard normal shock $\epsilon_{it}$ which is identically and independently distributed, and the former is determined as a function of our opponent's decision $a_{it}$.

Equilibrium conditions hold when being active is the best response for expected private information regarding $\epsilon_{it}(a_{it})$, and where $\sigma_i(s)$ denotes ex ante beliefs of firm $i$ that firm $j \neq i$ will choose to be active in the state $s$.

\begin{equation}
( 1-\sigma_i(s) ) \cdot (\lambda M_t - \delta a_{-i,t}-(1-a_{i,t-1})\psi + \epsilon_{it}(1)) + \sigma_i(s) \cdot \epsilon_{it}(0) \geq 0
\end{equation}

\begin{equation}
p_i(s)=1-\Phi[ ( 1-\sigma_i(s) ) \cdot (\lambda M_t - \delta a_{-i,t}-(1-a_{i,t-1}) \cdot \psi)]
\end{equation}

\begin{equation}
\mathbf{p-\Psi(\sigma,\theta)=0}
\end{equation}

\noindent Given consistency in beliefs,

\begin{equation}
p_i(s)=1-\Phi[ ( 1-p_i(s) ) \cdot (\lambda M_t - \delta a_{-i,t}-(1-a_{i,t-1}) \cdot \psi)]
\end{equation}

\begin{equation}
\mathbf{p-\Psi(p,\theta)=0}
\end{equation}

\noindent Where $\mathbf{p}$ is the matrix of conditional probabilities,

\begin{equation}
\mathbf{p=\Psi(p,\theta)=} (p_i(s)^2 _{i=1})^3 _{s=1}
\end{equation}

\begin{equation}
\mathbf{p}=
\begin{pmatrix}
p_1(s=1) & p_2(s=1) \\
p_1(s=2) & p_2(s=2) \\
p_1(s=3) & p_2(s=3)
\end{pmatrix}
\end{equation}

\newpage

\subsection{Value Function}

A Markov Perfect Equilibrium is characterised by $\mathbf{(a, \sigma)}$ representing a best response $a_i$ for firm $i$ to the opposite firm's action $a_{-i}$ given beliefs $\sigma_i$ across all states $s$ in the state space. Additionally, all firms will employ Markovian strategies and hold beliefs consistent with their strategies.

Given that the profit function is additive in shocks,

\begin{equation}
\Pi_{it}(a_t, s_t, \epsilon_{it}) = \Pi_{it}(a_t, s_t) + \epsilon_{it}(a_{it})
\end{equation}

\begin{equation}
\Pi_{it}(a_t, s_t, \epsilon_{it}) = \mathbf{1} (a_{it}=1) \cdot [ \lambda M_t - \delta a_{-i,t} - (1-a_{i,t-1}) \cdot \psi ] + \epsilon_{it}(a_{it})
\end{equation}

\begin{equation}
\begin{split}
\bar{\Pi}_{it}(a_t, s_t, \epsilon_{it}) = \mathbf{1} (a_{it}=1) \cdot [ \lambda M_t - \delta a_{-i,t} - (1-a_{i,t-1}) \cdot \psi ] \\ + \sum_{k=1} ^K \epsilon_{it}^k (a_{it}) \cdot \mathbf{1}(a_{i}^t=k)
\end{split}
\end{equation}

\noindent Through simplification we then arrive at our ex ante value function,

\begin{equation}
\begin{split}
V_i(s,\sigma_i)=\sum_{a \in A} \sigma_i(a|s) \cdot [ \mathbf{1} (a_{it}=1) \cdot [ \lambda M_t - \delta a_{-i,t} - (1-a_{i,t-1}) \cdot \psi ] \\ + \beta \sum_{s' \in S} g(a,s,s') \cdot V_i(s',\sigma_i) ] + \sum_{k=1} ^K E_{\epsilon} [ \epsilon_i ^k | a_i = k ] \cdot \sigma_i(a_i=k|s)
\end{split}
\end{equation}

\begin{equation}
\begin{split}
V_i(s,\sigma_i)=\sum_{a \in A} \sigma_i(a|s) \cdot [ \Pi_i(a,s) + \beta \sum_{s' \in S} g(a,s,s') \cdot V_i(s',\sigma_i) ] \\ + \sum_{k=1} ^K E_{\epsilon} [ \epsilon_i ^k | a_i = k ] \cdot \sigma_i(a_i=k|s)
\end{split}
\end{equation}

\noindent Subsequent conversion to matrix form yields the closed form solution of the value function,

\begin{equation}
\mathbf{V}_i(\sigma_i)=\mathbf{\sigma}_i \mathbf{\Pi}_i + \beta \mathbf{\sigma}_i \mathbf{GV}_i(\sigma_i) + \mathbf{D}_i(\sigma_i)
\end{equation}

\begin{equation}
\mathbf{V}_i(\sigma_i) - \beta \mathbf{\sigma}_i \mathbf{GV}_i(\sigma_i) =\mathbf{\sigma}_i \mathbf{\Pi}_i + \mathbf{D}_i(\sigma_i)
\end{equation}

\begin{equation}
\mathbf{(I - \beta \mathbf{\sigma}}_i \mathbf{G) V}_i(\sigma_i) =\mathbf{\sigma}_i \mathbf{\Pi}_i + \mathbf{D}_i(\sigma_i)
\end{equation}

\begin{equation}
\mathbf{V}_i(\sigma_i) = \mathbf{(I - \beta \mathbf{\sigma}}_i \mathbf{G})^{-1} [\mathbf{\sigma}_i \mathbf{\Pi}_i + \mathbf{D}_i(\sigma_i)]
\end{equation}

\noindent Parameters that have been specified include $\lambda=2, \delta=2, \psi=1.5$, and $\beta=0.95$.

\noindent The matrix designated as a component of the state variable vector is as follows,

\begin{equation}
M=\begin{pmatrix}
m_1\\m_2
\end{pmatrix}=
\begin{pmatrix}
1\\1.5
\end{pmatrix}
\end{equation}

\noindent The matrix designated as the Markovian state transition probabilities for $M$ is as follows,

\begin{equation}
\mathbf{G}=\begin{pmatrix}
b_{11} & b_{12} \\
b_{21} & b_{22}
\end{pmatrix}=
\begin{pmatrix}
0.5 & 0.5 \\
0.4 & 0.6
\end{pmatrix}
\end{equation}

\end{document}